{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWwrfbbVGOA"
   },
   "source": [
    "#### [LangChain Handbook](https://qdrant.tech/articles/langchain-integration/)\n",
    "\n",
    "# LangChain Retrieval Agent\n",
    "\n",
    "`Conversational agents` like chatgpt although being very accurate, face some issues with data freshness, accessing internal documentations and knowledge about specific domains. On the other hand `retrieval augmentation` solves these issues but then it would always retrieve on every query which is inefficient in most of simple cases in which retrieval is not required. Using both of these methods simultaneously gives us a system which can answer simple questions directly and seek for extra knowledge when queried with complex questions. We will see how to do so with LangChain and Qdrant in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "Let's get started by installing the packages needed for notebook to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pva9ehKXUpU2",
    "outputId": "3bbcf2dd-1889-412f-d45a-f56945ac4f2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU openai==0.27.8 qdrant-client==1.3.1 langchain==0.0.225 datasets==2.13.1 tiktoken==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from langchain.vectorstores import Qdrant\n",
    "import qdrant_client\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTgrOQziXUto"
   },
   "source": [
    "## Building the Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNyRsz0ZXXaq"
   },
   "source": [
    "Our knowledge base will be prepared from a dataset from Hugging Face called `vietgpt/multi_news_en`, it consists of about 45k records of news articles and human-written summaries of these articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laSDMjqQXuj-",
    "outputId": "5272df99-eb4b-4ec2-c513-504e067be2b6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/karti/.cache/huggingface/datasets/vietgpt___parquet/vietgpt--multi_news_en-4921e62a5a375465/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary'],\n",
       "    num_rows: 44972\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"vietgpt/multi_news_en\", split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8casaLEpX18U"
   },
   "source": [
    "We convert the dataset into a pandas dataframe for further use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "JnWZTcJiXzor",
    "outputId": "42659cec-23c3-4349-b007-676da99d834d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National Archives \\n \\n Yes, it’s that time ag...</td>\n",
       "      <td>– The unemployment rate dropped to 8.2% last m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOS ANGELES (AP) — In her first interview sinc...</td>\n",
       "      <td>– Shelly Sterling plans \"eventually\" to divorc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAITHERSBURG, Md. (AP) — A small, private jet ...</td>\n",
       "      <td>– A twin-engine Embraer jet that the FAA descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tucker Carlson Exposes His Own Sexism on Twitt...</td>\n",
       "      <td>– Tucker Carlson is in deep doodoo with conser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man accused of removing another man's testic...</td>\n",
       "      <td>– What are the three most horrifying words in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  National Archives \\n \\n Yes, it’s that time ag...   \n",
       "1  LOS ANGELES (AP) — In her first interview sinc...   \n",
       "2  GAITHERSBURG, Md. (AP) — A small, private jet ...   \n",
       "3  Tucker Carlson Exposes His Own Sexism on Twitt...   \n",
       "4  A man accused of removing another man's testic...   \n",
       "\n",
       "                                             summary  \n",
       "0  – The unemployment rate dropped to 8.2% last m...  \n",
       "1  – Shelly Sterling plans \"eventually\" to divorc...  \n",
       "2  – A twin-engine Embraer jet that the FAA descr...  \n",
       "3  – Tucker Carlson is in deep doodoo with conser...  \n",
       "4  – What are the three most horrifying words in ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to_pandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2_Pt7N6Zg2X"
   },
   "source": [
    "### Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGoS84KYZnSK"
   },
   "source": [
    "To store our data in qdrant we need to convert the data in vector representations which capture the semantic meaning of our data and later cosine similarity is used to match the query with our data to find the best matching data. There are many options for creating vector embeddings for our data. We will use OpenAI model `text-embedding-ada-002` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U57x2_87YSpb",
    "outputId": "cf4c99af-24b7-4bf5-97ea-71091c8fc2ce",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = (\n",
    "    \"text-embedding-ada-002\"  # will be used to create embeddings of summary column.\n",
    ")\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\"\n",
    "\n",
    "embed = OpenAIEmbeddings(model=model_name, openai_api_key=openai_api_key)\n",
    "embed  # will be use later while creating vector store with langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQTfOTR6aBRS"
   },
   "source": [
    "## Initialize Qdrant client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3wrG-9yaJel",
    "outputId": "842bf46f-fd0f-4322-8d90-a7fd769b7687",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[]\n",
      "collections=[CollectionDescription(name='langchain-retrieval-agent')]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Qdrant client\n",
    "\n",
    "current_folder = Path.cwd()  # Get the current folder\n",
    "qdrant_folder = current_folder / \"qdrant\"\n",
    "qdrant_folder.mkdir()  # Create qdrant folder to store collection\n",
    "\n",
    "client = QdrantClient(path=qdrant_folder.resolve())  # path to new qdrant folder\n",
    "\n",
    "collection_name = \"langchain-retrieval-agent\"\n",
    "\n",
    "collections = client.get_collections()\n",
    "print(collections)\n",
    "\n",
    "# only create collection if it doesn't exist\n",
    "if collection_name not in collections:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=1536,  # specifying dimensionality of vectors output by model\n",
    "            distance=models.Distance.COSINE,  # specifying which metric will be used to check similarity of vectors\n",
    "        ),\n",
    "    )\n",
    "collections = client.get_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD5IGOoLaVx7"
   },
   "source": [
    "## Generate Embeddings -> Store in Qdrant\n",
    "Now we will generate embeddings for our summary column. We will do so in batches which is much faster than doing it individually. And then send a single api call to upsert the batch (also much faster).\n",
    "\n",
    "In qdrant, we need an id (a unique value), embedding (embeddings for the summary column), and metadata for each document in the dataset. The metadata is a dictionary containing data relevant to our embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "321ebcd192fc41e0a7a2ba9c0e7b8556",
      "7c898f43b39545879013df760aa4f6f1",
      "1b5fe655986842a6afd4a2eb2c0f47fc",
      "76872ca737b64616aeacc90f2f7fc655",
      "0679733cce4f4b5eb25f8f56dc7ebe22",
      "71551fc297b54fb4a21d787d117e01a1",
      "b90283522431447b925b226431bb4fa6",
      "a03d372e8b4f456e8663e54c818e0fe9",
      "6fc773ccbc594fddbc1f2f0adaa96186",
      "07b47869f727455fb5ba67e99767c04c",
      "4b2e12a33584489690aaf69f51cd4a3b"
     ]
    },
    "id": "AhDcbRGTaWPi",
    "outputId": "dca5a4d0-5d19-4542-c26c-3073bfa13f2a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c2f1908c364c31a49f697f27a8a766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector count in collection: 44972\n",
      "CPU times: total: 3min 26s\n",
      "Wall time: 13min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 1024  # specify batch size according to your RAM and compute, higher batch size = more RAM usage\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)  # get end of batch\n",
    "    batch = data.iloc[i:i_end]  # extract batch\n",
    "    meta = batch.to_dict(orient=\"records\")  # first get metadata fields for this record\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(\n",
    "            input=batch[\"summary\"].tolist(), engine=model_name\n",
    "        )\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(\n",
    "                    input=batch[\"summary\"].tolist(), engine=model_name\n",
    "                )\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record[\"embedding\"] for record in res[\"data\"]]\n",
    "    ids = list(range(i, i_end))  # create unique IDs\n",
    "\n",
    "    # upsert to qdrant\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=models.Batch(ids=ids, vectors=embeds, payloads=meta),\n",
    "    )\n",
    "\n",
    "collection_vector_count = client.get_collection(\n",
    "    collection_name=collection_name\n",
    ").vectors_count\n",
    "print(f\"Vector count in collection: {collection_vector_count}\")\n",
    "assert collection_vector_count == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDUnLdy1b7G1"
   },
   "source": [
    "Let's check our collection info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiccGZKAb_Qo",
    "outputId": "5cafd8c8-771f-46d0-e261-12c9b5b1b058",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=44972, indexed_vectors_count=0, points_count=44972, segments_count=1, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=None, replication_factor=None, write_consistency_factor=None, on_disk_payload=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=None, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-3oolT5cCR8"
   },
   "source": [
    "## Creating a Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcZ12U06cCH5"
   },
   "source": [
    "We will reuse the same collection to create a vector store of langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "0MBJ477-cFNw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.qdrant.Qdrant at 0x1c4308d7e50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embeddings=embed,\n",
    "    content_payload_key=\"summary\",\n",
    ")\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying\n",
    "Now with the help of langchain we can directly do `similarity search`(without generation component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='– A federal law enforcement official called today\\'s fatal explosions in Boston a \"terrorist attack\" but said it wasn\\'t clear whether the responsible party was foreign or domestic, CNN reports. Meanwhile speculation, dread, and political agendas are swirling around the Internet as the story unfolds. Slate notes the Patriot\\'s Day connection, reporting that other major attacks occurred on or around the holiday, including the Columbine School shooting (1999), the Oklahoma City bombing (1995), and the Waco assault (1993). In fact, Waco inspired anti-government activists to hold their own darker version of Patriot\\'s Day. Radio host Alex Jones tweets that the attacks look like a \"false flag\" operation, meaning he thinks the government or some other powerful group perpetrated the attacks for political reasons, reports Mediaite. The Washington Post reports that in the Middle East and elsewhere, the message \"Please Don\\'t Be a Muslim\" has been retweeted hundreds of times about the culprit; \"The thought of every Muslim right now,\" added a Dubai-based journalist. The head of the Muslim Writer’s Guild of America tweeted, \"Whoever the culprit, no religion justifies this act of violence. We must remain united against extremism.\"', metadata={}),\n",
       " Document(page_content='– Amid heightened security as the nation marks a decade since 9/11, feds are investigating threats posted on the White House\\'s Facebook page, reports NBC New York. \"We\\'ll come back U.S.A. One day only 11/9/2011,\" says one post, which shows a photo of Osama bin Laden. The second and third: \"We\\'ll come to u white house sooooooooooon,\" and \"We\\'ll come back 11/9/2011 to kill u all.\" As the AP reports, White House counterterror adviser John Brennan says the administration is taking the threat of an attack today very seriously, calling a previously reported threat \"specific and credible,\" but not \"confirmed.\" \"This is a 24/7, round-the-clock effort by all elements of the US counterterrorism community both here in the United States as well as abroad.\" In other news, feds are questioning a man in Kansas City after finding a suspicious object in his bag. He was uncooperative, notes the AP.', metadata={}),\n",
       " Document(page_content='– Rudy Giuliani has some advice about terrorism for President Obama: Follow George W. Bush\\'s example, because “we had no domestic attacks under Bush.” Dubbing American\\'s Mayor \"Mr. 9/11,\" Talking Points Memo points out that Sept. 11, 2001 was well into Bush’s tenure. As was shoe bomber Richard Reid\\'s attempt to blow up a flight from Paris to Miami in December 2001. What\\'s more, \"supposed journalist George Stephanopoulos does not bother to challenge this statement,\" Alex Pareene of Gawker notes in recapping the Good Morning America interview.', metadata={})]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"When did the biggest terror attack on USA happen?\"\n",
    "qdrant.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zGF6YsgczqT"
   },
   "source": [
    "Looks like we're getting good results. Let's take a look at how we can begin integrating this into a conversational agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFsIOm73dcOI"
   },
   "source": [
    "## Initializing the Conversational Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMv6TXWkdfNR"
   },
   "source": [
    "We will use `gpt-3.5-turbo` as out chat LLM, we will also need `conversational memory` to store previous conversations and a `RetrievalQA` chain to retrieve extra data when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "zMRs9Klic5-Y"
   },
   "outputs": [],
   "source": [
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo\", temperature=0.0\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", k=5, return_messages=True\n",
    ")\n",
    "# retrieval qa chain using vector store\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=qdrant.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ySfWyZLdboX"
   },
   "source": [
    "Now we can generate answer to our query using the `run` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LaYSq0V-dxHw",
    "outputId": "a85730a3-ab15-49b6-8aba-6da774fd3e3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The biggest terror attack on the USA happened on September 11, 2001, commonly referred to as 9/11.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtSXR5RXdyU0"
   },
   "source": [
    "For doing retrieval augmentation we also need to convert the previously initialized retrieval chain into a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "FwCYrS4duqBW"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Knowledge Base\",\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            \"use this tool when answering general knowledge queries to get \"\n",
    "            \"more information about the topic\"\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXi_0ipTvM_l"
   },
   "source": [
    "Now we can initialize the agent like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "JaKTzPUEvOoy"
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    agent=\"chat-conversational-react-description\",  # the type of agent to use\n",
    "    tools=tools,  # providing with retrieval chain tool\n",
    "    llm=llm,  # chat llm\n",
    "    verbose=True,  # to print additional information during execution\n",
    "    max_iterations=3,  # maximum iterations agent performs before stopping\n",
    "    early_stopping_method=\"generate\",  # method used to determine when to stop early\n",
    "    memory=conversational_memory,  # memory agent used, we are using ConversationBufferWindowMemory\n",
    "    handle_parsing_errors=True,  # to handle parsing errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbXl-AzVvszB"
   },
   "source": [
    "Now all the components are ready.\n",
    "We just need to pass our query to the agent to generate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJoAhy76vzAB",
    "outputId": "31ae7589-e66a-4835-d1d8-555bb59c962c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"biggest terror attack on USA date\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe biggest terror attack on the USA to date is the September 11, 2001 attacks, commonly referred to as 9/11.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The biggest terror attack on the USA to date is the September 11, 2001 attacks, commonly referred to as 9/11.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When did the biggest terror attack on USA happen?',\n",
       " 'chat_history': [],\n",
       " 'output': 'The biggest terror attack on the USA to date is the September 11, 2001 attacks, commonly referred to as 9/11.'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcMqa9Va2hU6"
   },
   "source": [
    "We get the correct answer, and it generates the answer from the observation. Now let's see for a common question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85vipqC02deV",
    "outputId": "345c724e-eaea-4a20-9445-99794bc743fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The product of 2 multiplied by 7 is 14.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 2 * 7?',\n",
       " 'chat_history': [HumanMessage(content='When did the biggest terror attack on USA happen?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The biggest terror attack on the USA to date is the September 11, 2001 attacks, commonly referred to as 9/11.', additional_kwargs={}, example=False)],\n",
       " 'output': 'The product of 2 multiplied by 7 is 14.'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"what is 2 * 7?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR_b0IN32rQ9"
   },
   "source": [
    "This time the agent do not refer to external knowledge and directly answers the question. Also we can see the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQeicHTj2pmY",
    "outputId": "9810647d-0846-4ca8-ae2e-1b249ca4ad3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"factors that account for GDP growth of a country\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThere are several factors that can account for GDP growth of a country. Some of the key factors include:\n",
      "\n",
      "1. Consumer spending: Increased consumer spending on goods and services can contribute to GDP growth. When consumers have more disposable income and confidence in the economy, they are more likely to spend, which stimulates economic growth.\n",
      "\n",
      "2. Investment: Both private and public investment in infrastructure, businesses, and technology can drive GDP growth. Investment leads to increased production capacity, job creation, and innovation, all of which contribute to economic expansion.\n",
      "\n",
      "3. Government spending: Government expenditure on public goods and services, such as education, healthcare, and defense, can have a significant impact on GDP growth. Government spending can stimulate economic activity and create jobs.\n",
      "\n",
      "4. Exports and imports: The balance of trade, which is the difference between a country's exports and imports, can affect GDP growth. A positive balance of trade, where exports exceed imports, can contribute to economic growth by increasing revenue and creating jobs.\n",
      "\n",
      "5. Labor force and productivity: The size and productivity of the labor force play a crucial role in GDP growth. A larger labor force can lead to increased production, while higher productivity levels can result in more output per worker.\n",
      "\n",
      "6. Technological advancements: Technological progress and innovation can drive economic growth by improving productivity, efficiency, and competitiveness. Advancements in technology can lead to new industries, products, and services, creating economic opportunities.\n",
      "\n",
      "7. Monetary and fiscal policies: The policies implemented by the government and central bank, such as interest rates, taxation, and government spending, can impact GDP growth. Expansionary monetary and fiscal policies can stimulate economic activity, while contractionary policies can slow down growth.\n",
      "\n",
      "It's important to note that these factors can interact with each other and vary in their significance depending on the specific country and its economic conditions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"There are several factors that can account for GDP growth of a country. Some of the key factors include consumer spending, investment, government spending, exports and imports, labor force and productivity, technological advancements, and monetary and fiscal policies. These factors can interact with each other and vary in their significance depending on the specific country and its economic conditions.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the most important factors that account for the GDP growth of a country?',\n",
       " 'chat_history': [HumanMessage(content='When did the biggest terror attack on USA happen?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The biggest terror attack on the USA to date is the September 11, 2001 attacks, commonly referred to as 9/11.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='what is 2 * 7?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The product of 2 multiplied by 7 is 14.', additional_kwargs={}, example=False)],\n",
       " 'output': 'There are several factors that can account for GDP growth of a country. Some of the key factors include consumer spending, investment, government spending, exports and imports, labor force and productivity, technological advancements, and monetary and fiscal policies. These factors can interact with each other and vary in their significance depending on the specific country and its economic conditions.'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\n",
    "    \"What are the most important factors that account for the GDP growth of a country?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Certainly! Here's a summary of the factors that account for GDP growth in a country: Consumer spending, investment, government spending, exports and imports, labor force and productivity, technological advancements, and monetary and fiscal policies all play important roles in driving GDP growth. These factors interact and vary in significance depending on the specific country and its economic conditions.\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Several factors contribute to GDP growth in a country, including consumer spending, investment, government spending, exports and imports, labor force and productivity, technological advancements, and monetary and fiscal policies.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'can you summarize these facts in two short sentences',\n",
       " 'chat_history': [HumanMessage(content='When did the biggest terror attack on USA happen?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The biggest terror attack on the USA to date is the September 11, 2001 attacks, commonly referred to as 9/11.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='what is 2 * 7?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The product of 2 multiplied by 7 is 14.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='What are the most important factors that account for the GDP growth of a country?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='There are several factors that can account for GDP growth of a country. Some of the key factors include consumer spending, investment, government spending, exports and imports, labor force and productivity, technological advancements, and monetary and fiscal policies. These factors can interact with each other and vary in their significance depending on the specific country and its economic conditions.', additional_kwargs={}, example=False)],\n",
       " 'output': 'Several factors contribute to GDP growth in a country, including consumer spending, investment, government spending, exports and imports, labor force and productivity, technological advancements, and monetary and fiscal policies.'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"can you summarize these facts in two short sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWivmw9F3bCw"
   },
   "source": [
    "We are getting the answers in the way we wanted. The agent can refer to previous conversation as a source of information as well as decide when to look for external knowledge and when to answer without it.\n",
    "That's all we wanted to showcase. You can do more queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa1whr8V3Wfm"
   },
   "outputs": [],
   "source": [
    "client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykg5TYA033yR"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0679733cce4f4b5eb25f8f56dc7ebe22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07b47869f727455fb5ba67e99767c04c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b5fe655986842a6afd4a2eb2c0f47fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a03d372e8b4f456e8663e54c818e0fe9",
      "max": 189,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fc773ccbc594fddbc1f2f0adaa96186",
      "value": 189
     }
    },
    "321ebcd192fc41e0a7a2ba9c0e7b8556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c898f43b39545879013df760aa4f6f1",
       "IPY_MODEL_1b5fe655986842a6afd4a2eb2c0f47fc",
       "IPY_MODEL_76872ca737b64616aeacc90f2f7fc655"
      ],
      "layout": "IPY_MODEL_0679733cce4f4b5eb25f8f56dc7ebe22"
     }
    },
    "4b2e12a33584489690aaf69f51cd4a3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fc773ccbc594fddbc1f2f0adaa96186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "71551fc297b54fb4a21d787d117e01a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76872ca737b64616aeacc90f2f7fc655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07b47869f727455fb5ba67e99767c04c",
      "placeholder": "​",
      "style": "IPY_MODEL_4b2e12a33584489690aaf69f51cd4a3b",
      "value": " 189/189 [03:23&lt;00:00,  1.12s/it]"
     }
    },
    "7c898f43b39545879013df760aa4f6f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71551fc297b54fb4a21d787d117e01a1",
      "placeholder": "​",
      "style": "IPY_MODEL_b90283522431447b925b226431bb4fa6",
      "value": "100%"
     }
    },
    "a03d372e8b4f456e8663e54c818e0fe9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b90283522431447b925b226431bb4fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
